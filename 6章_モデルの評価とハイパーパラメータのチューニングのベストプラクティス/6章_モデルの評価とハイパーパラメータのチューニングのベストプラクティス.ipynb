{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章では次の内容を取り上げる。\n",
    "\n",
    "- モデルの性能の偏りのない推定量の算出\n",
    "- 機会学習のアルゴリズムに共通する問題の診断\n",
    "- 機会学習のモデルのチューニング\n",
    "- さまざまな性能指標に基づく予測モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 パイプラインによるワークフローの効率化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/'\n",
    "                'breast-cancer-wisconsin/wdbc.data',\n",
    "                header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30個の特徴量をNumpy配列のオブジェクトXに割り当てる。LabelEncoderを使用することで、元のクラスラベルの文字列表現('M'および'B')を整数に変換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.loc[:,2:].values\n",
    "y = df.loc[:,1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配列yに格納されたクラスラベルを符号化した後は、悪性クラス1、良性クラス0で表されるようになる。具体的に示すには、適合されたLabelEncoderのtransformメソッドを呼び出し、2つのダミークラスラベルを渡せばよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(['M','B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをトレニンーグデータセットとテストデータセットに分割(8:2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=20,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 パイプラインで変換器と推定器を結合する\n",
    "最適な性能を得るために入力特徴量の尺度をそろえる。そのため標準化して、ロジスティクス回帰といった線形分類器に入力できるようにする。さらに**主成分分析(PCA)**を使用し、データを最初の30次元から2次元の部分空間に圧縮する。\n",
    "トレーニングデータセットとテストデータセットの学習と変換を別々に行う代わりにStandardScaler,PCA,LogisticRegressionの3つのオブジェクトをパイプラインで結合する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# 連結する処理としてスケーリング、主成分分析、ロジスティクス回帰を指定\n",
    "pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=2),LogisticRegression(random_state=1))\n",
    "pipe_lr.fit(X_train,y_train)\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 k分割交差検証を使ったモデルの性能の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Class dist.:[309 184] ,Acc: 0.946\n",
      "Fold:  2, Class dist.:[309 184] ,Acc: 0.964\n",
      "Fold:  3, Class dist.:[309 184] ,Acc: 0.946\n",
      "Fold:  4, Class dist.:[309 184] ,Acc: 0.964\n",
      "Fold:  5, Class dist.:[310 184] ,Acc: 0.964\n",
      "Fold:  6, Class dist.:[310 185] ,Acc: 0.926\n",
      "Fold:  7, Class dist.:[310 185] ,Acc: 0.944\n",
      "Fold:  8, Class dist.:[310 185] ,Acc: 0.963\n",
      "Fold:  9, Class dist.:[310 185] ,Acc: 0.963\n",
      "Fold: 10, Class dist.:[310 185] ,Acc: 0.963\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 分割データ、分割数、乱数背姿勢器の状態を指定し、\n",
    "# 層化k分割交差検証イテレータを表すStratifiedKFoldクラスのインスタンス化\n",
    "kfold = StratifiedKFold(n_splits=10,random_state=1).split(X_train,y_train)\n",
    "scores = []\n",
    "\n",
    "\"\"\"\n",
    "イテレータのインデックスと要素をループ処理：（上から順に）\n",
    "    データをモデルに適合\n",
    "    テストデータの正解率を算出\n",
    "    リストに正解率を追加\n",
    "    分割の番号、0以上の要素数、正解率を出力\n",
    "\"\"\"\n",
    "for k ,(train,test)in enumerate(kfold):\n",
    "    # print(X_train[train])\n",
    "    pipe_lr.fit(X_train[train],y_train[train])\n",
    "    score = pipe_lr.score(X_train[test],y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.:%s ,Acc: %.3f' % \n",
    "         (k+1,np.bincount(y_train[train]),score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy: 0.954 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "# 正解率の平均と標準偏差を出力\n",
    "print('\\nCV accuracy: %.3f +/- %.3f'% (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learnにk分割交差検証の性能指標を算出する関数も実装されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores:[0.94642857 0.96428571 0.94642857 0.96428571 0.96363636 0.92592593\n",
      " 0.94444444 0.96296296 0.96296296 0.96296296]\n",
      "CV accuracy: 0.954 +/- 0.012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# 交差検証のcross_val_score関数でモデルの正解率を算出\n",
    "# 推定量estimator、トレーニングデータX、予測値y、分割数cv、CPU数n_jobsを指定\n",
    "scores = cross_val_score(estimator=pipe_lr,X=X_train,y=y_train,\n",
    "                        cv=10,n_jobs=1)\n",
    "print('CV accuracy scores:%s' % scores)\n",
    "\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 学習曲線と検証曲線によるアルゴリズムの診断\n",
    "学習アルゴリズムの性能を向上させるのに役立つ**学習曲線(learning curve)**と**検証曲線(validation curve)**を取り上げる。\n",
    "過学習（バリアンスが高い）または学習不足（バイアスが高い）の問題があるかどうかを、学習曲線を使用し診断する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 学習曲線を使ってバイアスとバリアンスの問題を診断する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "pipe_lr = make_pipeline(StandardScaler(),\n",
    "                       LogisticRegression(penalty='l2',random_state=1))\n",
    "# learning_curve関数で交差検証による正解率を算出\n",
    "train_sizes,train_scores,test_scores = learning_curve(estimator=pipe_lr,\n",
    "                                                     X=X_train,\n",
    "                                                     y=y_train,\n",
    "                                                     train_sizes=np.linspace(0.1,1.0,10),\n",
    "                                                     cv=10,\n",
    "                                                     n_jobs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
